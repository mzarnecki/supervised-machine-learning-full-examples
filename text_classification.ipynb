{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !IMPORTANT - to run this notebook download first \"corpus\" dataset from \n",
    "# dataset https://gist.github.com/kunalj101/ad1d9c58d338e20d09ff26bcc06c4235 and put it in same folder as for this notebook\n",
    "# then import wiki-news-300d-1M.vec from https://www.kaggle.com/datasets/facebook/fasttext-wikinews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/michal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/michal/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text       label\n",
      "0   Stuning even for the non-gamer: This sound tra...  __label__2\n",
      "1   The best soundtrack ever to anything.: I'm rea...  __label__2\n",
      "2   Amazing!: This soundtrack is my favorite music...  __label__2\n",
      "3   Excellent Soundtrack: I truly like this soundt...  __label__2\n",
      "4   Remember, Pull Your Jaw Off The Floor After He...  __label__2\n",
      "..                                                ...         ...\n",
      "95  Very Not Worth Your Time: The book was wriiten...  __label__1\n",
      "96  Very fun and educational: Trains, shapes and p...  __label__2\n",
      "97  Ludicrous and silly: I remember getting this b...  __label__1\n",
      "98  Artistry: I think that the Deodato concerts ar...  __label__2\n",
      "99  Caution!: These tracks are not the \"original\" ...  __label__1\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "                                                     text       label\n",
      "count                                               10000       10000\n",
      "unique                                              10000           2\n",
      "top     Stuning even for the non-gamer: This sound tra...  __label__1\n",
      "freq                                                    1        5097\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import ensemble\n",
    "from keras import layers, models, optimizers\n",
    "import numpy\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# import dataset\n",
    "# __label__2 - positive review\n",
    "# __label__1 - negative review\n",
    "data = open('corpus').read()\n",
    "\n",
    "#fill lists with reviews and labels\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")): \n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# create DataFrame\n",
    "trainDF = pd.DataFrame()\n",
    "# add texts to DataFrame\n",
    "trainDF['text'] = texts\n",
    "# add labels to DataFrame\n",
    "trainDF['label'] = labels\n",
    "\n",
    "#display first 100 records\n",
    "print(trainDF.head(100))\n",
    "#show statics information\n",
    "print(trainDF.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  word_count\n",
      "0  Stuning even for the non-gamer: This sound tra...          80\n",
      "1  The best soundtrack ever to anything.: I'm rea...          97\n",
      "2  Amazing!: This soundtrack is my favorite music...         129\n",
      "3  Excellent Soundtrack: I truly like this soundt...         118\n",
      "4  Remember, Pull Your Jaw Off The Floor After He...          87\n",
      "212\n",
      "14\n",
      "79.5532\n"
     ]
    }
   ],
   "source": [
    "# analyze dataset\n",
    "# check number of words in each review\n",
    "train = trainDF.copy()\n",
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "print(train[['text','word_count']].head())\n",
    "print(train['word_count'].max())\n",
    "print(train['word_count'].min())\n",
    "print(train['word_count'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  char_count\n",
       "0  Stuning even for the non-gamer: This sound tra...         426\n",
       "1  The best soundtrack ever to anything.: I'm rea...         509\n",
       "2  Amazing!: This soundtrack is my favorite music...         760\n",
       "3  Excellent Soundtrack: I truly like this soundt...         743\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...         481"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check character number\n",
    "train['char_count'] = train['text'].str.len() ## this also includes spaces\n",
    "train[['text','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>4.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>4.257732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>4.899225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>5.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>4.540230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  avg_word\n",
       "0  Stuning even for the non-gamer: This sound tra...  4.337500\n",
       "1  The best soundtrack ever to anything.: I'm rea...  4.257732\n",
       "2  Amazing!: This soundtrack is my favorite music...  4.899225\n",
       "3  Excellent Soundtrack: I truly like this soundt...  5.305085\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  4.540230"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check average word length\n",
    "\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['text'].apply(lambda x: avg_word(x))\n",
    "train[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stopwords\n",
       "0  Stuning even for the non-gamer: This sound tra...         29\n",
       "1  The best soundtrack ever to anything.: I'm rea...         42\n",
       "2  Amazing!: This soundtrack is my favorite music...         48\n",
       "3  Excellent Soundtrack: I truly like this soundt...         33\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...         28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of stop-words (stop-words are common words not important for analysis)\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train[['text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  numerics\n",
      "0  Stuning even for the non-gamer: This sound tra...         0\n",
      "1  The best soundtrack ever to anything.: I'm rea...         0\n",
      "2  Amazing!: This soundtrack is my favorite music...         1\n",
      "3  Excellent Soundtrack: I truly like this soundt...         0\n",
      "4  Remember, Pull Your Jaw Off The Floor After He...         0\n",
      "13\n",
      "0\n",
      "0.3557\n"
     ]
    }
   ],
   "source": [
    "# check numeric characters number\n",
    "\n",
    "train['numerics'] = train['text'].apply(lambda x: len([x for x in x.split(' ') if x.isnumeric()]))\n",
    "print(train[['text','numerics']].head())\n",
    "print(train['numerics'].max())\n",
    "print(train['numerics'].min())\n",
    "print(train['numerics'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  upper\n",
      "0  Stuning even for the non-gamer: This sound tra...      3\n",
      "1  The best soundtrack ever to anything.: I'm rea...      3\n",
      "2  Amazing!: This soundtrack is my favorite music...      4\n",
      "3  Excellent Soundtrack: I truly like this soundt...      4\n",
      "4  Remember, Pull Your Jaw Off The Floor After He...      0\n",
      "179\n",
      "0\n",
      "11.2266\n"
     ]
    }
   ],
   "source": [
    "# check number of upper case letters\n",
    "\n",
    "train['upper'] = train['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "print(train[['text','upper']].head())\n",
    "\n",
    "train['capital'] = train['text'].apply(lambda x: len([x for x in x.split(' ') if x[0].isupper()]))\n",
    "print(train['capital'].max())\n",
    "print(train['capital'].min())\n",
    "print(train['capital'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  upper\n",
      "0  Stuning even for the non-gamer: This sound tra...      3\n",
      "1  The best soundtrack ever to anything.: I'm rea...      3\n",
      "2  Amazing!: This soundtrack is my favorite music...      4\n",
      "3  Excellent Soundtrack: I truly like this soundt...      4\n",
      "4  Remember, Pull Your Jaw Off The Floor After He...      0\n",
      "179\n",
      "0\n",
      "11.2266\n"
     ]
    }
   ],
   "source": [
    "# check number of punctuation characters\n",
    "\n",
    "train['punctuation'] = train['text'].apply(lambda x: len(re.findall(r'[\\.,?!;:]', x)))\n",
    "print(train[['text','upper']].head())\n",
    "\n",
    "train['punctuation'] = train['text'].apply(lambda x: len([x for x in x.split(' ') if x[0].isupper()]))\n",
    "print(train['punctuation'].max())\n",
    "print(train['punctuation'].min())\n",
    "print(train['punctuation'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    stuning even for the non-gamer: this sound tra...\n",
       "1    the best soundtrack ever to anything.: i'm rea...\n",
       "2    amazing!: this soundtrack is my favorite music...\n",
       "3    excellent soundtrack: i truly like this soundt...\n",
       "4    remember, pull your jaw off the floor after he...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize text\n",
    "# apply lowercase\n",
    "\n",
    "trainDFRaw = trainDF.copy()\n",
    "\n",
    "trainDF['text'] = trainDF['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "trainDF['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13002/522430754.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trainDF['text'] = trainDF['text'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    stuning even for the nongamer this sound track...\n",
       "1    the best soundtrack ever to anything im readin...\n",
       "2    amazing this soundtrack is my favorite music o...\n",
       "3    excellent soundtrack i truly like this soundtr...\n",
       "4    remember pull your jaw off the floor after hea...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove special characters\n",
    "\n",
    "trainDF['text'] = trainDF['text'].str.replace('[^\\w\\s]','')\n",
    "trainDF['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    stuning even nongamer sound track beautiful pa...\n",
       "1    best soundtrack ever anything im reading lot r...\n",
       "2    amazing soundtrack favorite music time hands i...\n",
       "3    excellent soundtrack truly like soundtrack enj...\n",
       "4    remember pull jaw floor hearing youve played g...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usunięcie słów \"stopwords\"\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "trainDF['text'] = trainDF['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "trainDF['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book      6496\n",
       "one       3857\n",
       "like      2813\n",
       "good      2769\n",
       "read      2740\n",
       "great     2719\n",
       "movie     2543\n",
       "would     2381\n",
       "get       1931\n",
       "time      1903\n",
       "dont      1771\n",
       "really    1604\n",
       "first     1444\n",
       "much      1419\n",
       "even      1400\n",
       "well      1362\n",
       "story     1334\n",
       "buy       1233\n",
       "love      1193\n",
       "best      1107\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare list of most frequent words\n",
    "\n",
    "freq = pd.Series(' '.join(trainDF['text']).split()).value_counts()[:20]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    stuning nongamer sound track beautiful paints ...\n",
       "1    soundtrack ever anything im reading lot review...\n",
       "2    amazing soundtrack favorite music hands intens...\n",
       "3    excellent soundtrack truly soundtrack enjoy vi...\n",
       "4    remember pull jaw floor hearing youve played g...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove most frequent words\n",
    "\n",
    "freq = list(freq.index)\n",
    "trainDF['text'] = trainDF['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "trainDF['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "christmasand          1\n",
       "550                   1\n",
       "childrenguaranteed    1\n",
       "marriedwith           1\n",
       "roommatesa            1\n",
       "bathtub               1\n",
       "sooooooooooo          1\n",
       "rulz                  1\n",
       "killer06              1\n",
       "seasonalready         1\n",
       "dogs05                1\n",
       "niece04               1\n",
       "four03                1\n",
       "house02               1\n",
       "episodes01            1\n",
       "goodhere              1\n",
       "dvdbut                1\n",
       "outno                 1\n",
       "timesjohn             1\n",
       "graduation            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare list of rare words\n",
    "\n",
    "freq = pd.Series(' '.join(trainDF['text']).split()).value_counts()[-20:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    stuning nongamer sound track beautiful paints ...\n",
       "1    soundtrack ever anything im reading lot review...\n",
       "2    amazing soundtrack favorite music hands intens...\n",
       "3    excellent soundtrack truly soundtrack enjoy vi...\n",
       "4    remember pull jaw floor hearing youve played g...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rare words\n",
    "\n",
    "freq = list(freq.index)\n",
    "trainDF['text'] = trainDF['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "trainDF['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tuning nongamer sound track beautiful points s...\n",
       "1    soundtrack ever anything in reading lot review...\n",
       "2    amazing soundtrack favorite music hands intens...\n",
       "3    excellent soundtrack truly soundtrack enjoy vi...\n",
       "4    remember pull jaw floor hearing you played gam...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix typos\n",
    "\n",
    "from textblob import TextBlob\n",
    "trainDF['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/michal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    stuning nongamer sound track beautiful paint s...\n",
       "1    soundtrack ever anything im reading lot review...\n",
       "2    amazing soundtrack favorite music hand intense...\n",
       "3    excellent soundtrack truly soundtrack enjoy vi...\n",
       "4    remember pull jaw floor hearing youve played g...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatize - unify words with same language core\n",
    "\n",
    "from textblob import Word\n",
    "nltk.download('wordnet')\n",
    "\n",
    "trainDF = trainDF.copy()\n",
    "trainDF['text'] = trainDF['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "trainDF['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prepare model\n",
    "# split data to train and test set\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# encode categorical values\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "print(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode text to TF-IDF numeric vectors\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal method for model training\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # train model\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # generate predictions for test set\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    # evaluate model\n",
    "    scores = list(metrics.precision_recall_fscore_support(predictions, valid_y))\n",
    "    score_vals = [\n",
    "        scores[0][0],\n",
    "        scores[1][0],\n",
    "        scores[2][0]\n",
    "    ]\n",
    "    score_vals.append(metrics.accuracy_score(predictions, valid_y))\n",
    "    return score_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, WordLevel TF-IDF:  [0.8401898734177216, 0.8408551068883611, 0.8405223585278987, 0.8388]\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1 - logistic regression\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "accuracy_compare = {'LR': accuracy}\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  [0.8393987341772152, 0.8413957176843775, 0.8403960396039605, 0.8388]\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2 - Support Vector Machine\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "accuracy_compare['SVM'] = accuracy\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, WordLevel TF-IDF:  [0.8188291139240507, 0.7894736842105263, 0.8038834951456312, 0.798]\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3 - Random Forest Tree \n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "accuracy_compare['RF'] = accuracy\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wiki-news-300d-1M.vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# load the pre-trained word-embedding vectors \u001b[39;00m\n\u001b[1;32m      6\u001b[0m embeddings_index \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwiki-news-300d-1M.vec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[1;32m      8\u001b[0m     values \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      9\u001b[0m     embeddings_index[values[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(values[\u001b[38;5;241m1\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wiki-news-300d-1M.vec'"
     ]
    }
   ],
   "source": [
    "# coding words as vectors with encoded meaning - word embeddings\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 4 - convolutional neural network with word embeddings\n",
    "\n",
    "def create_cnn():\n",
    "    # add input layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # add encoding layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # add convolutional layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # add connection layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # add aoutput layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # compile model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_cnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "accuracy_compare['CNN'] = accuracy\n",
    "print (\"CNN, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models\n",
    "# compare models\n",
    "\n",
    "df_compare = pd.DataFrame(accuracy_compare, index = ['precision', 'recall', 'f1 score', 'accuracy'])\n",
    "df_compare.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without text normalization\n",
    "\n",
    "# split to train and test set\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDFRaw['text'], trainDFRaw['label'])\n",
    "\n",
    "# encode to numeric vectors\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "# encode as TF-IDF\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# MODEL 1 - logistic regression\n",
    "accuracy_compare['LRRaw'] = accuracy\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "\n",
    "df_compare = pd.DataFrame(accuracy_compare, index = ['precision', 'recall', 'f1 score', 'accuracy'])\n",
    "df_compare.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
